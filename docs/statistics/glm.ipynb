{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182a3d6",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from config import *\n",
    "\n",
    "!cp ../data/msleep.txt .\n",
    "!cp ../data/flowering.txt ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e64074-81dd-40fe-8daf-9029bcf3fed4",
   "metadata": {},
   "source": [
    "# 一般化線形モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede7719",
   "metadata": {},
   "source": [
    "[回帰分析](線形回帰)では、目的変数をモデル化した際に生じる誤差が正規分布に従うことを仮定しています。例えば、目的変数 $ Y $ を、説明変数 $ X_{1}, X_{2}, \\cdots, X_{n} $ でモデル化したとします。\n",
    "\n",
    "$$\n",
    "Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\cdots + \\beta_{n}X_{n} + \\epsilon\n",
    "$$\n",
    "\n",
    "このとき、誤差項 $\\epsilon$ は正規分布に従う必要があります。もしモデルを評価した際に、誤差項が正規分布から大きく外れている場合は、モデルが妥当でない可能性があります。そのような場合は、誤差の分布の特徴に応じて適切な分布を仮定し解析を行う**一般化線形モデル**（**generalized linear model**; **GLM**）を用いることで、より適切なモデルが得られることが多いです。本節では、この一般化線形モデルについて説明します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9780e",
   "metadata": {},
   "source": [
    "## 線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ccf01",
   "metadata": {},
   "source": [
    "一般化線形モデルのうち、誤差項が正規分布に従う場合には、これを回帰分析と呼ぶことがあります。そのため、一般化線形モデルの枠組みを用いて回帰分析を行うことも可能です。哺乳類の睡眠時間のデータを例にとり、睡眠時間（TotalSleep）を使って、寿命（LifeSpan）を説明する回帰モデルを構築してみよう。\n",
    "\n",
    "まず、データを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09678a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://py.biopapyrus.jp/data/msleep.txt\n",
    "msleep = pd.read_csv('msleep.txt', sep='\\t', comment='#')\n",
    "msleep = msleep.dropna()\n",
    "msleep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e385954",
   "metadata": {},
   "source": [
    "次に、statsmodels ライブラリ api モジュールの `GLM` 関数を用いて回帰分析を行います。この関数は `OLS` 関数と同様に、目的変数と説明変数を順に引数として渡して使用します。また、モデルに定数項（切片）を含めるため、説明変数にすべての値が 1 の列を追加する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = msleep['LifeSpan']\n",
    "X = msleep['TotalSleep']\n",
    "\n",
    "m_lm = sm.GLM(y, sm.add_constant(X))\n",
    "fit_lm = m_lm.fit()\n",
    "\n",
    "fit_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd115146",
   "metadata": {},
   "source": [
    "推定された回帰直線と実際の観測値をグラフに描き、モデルを可視化してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(X.min(), X.max(), 100)\n",
    "y_ = fit_lm.get_prediction(sm.add_constant(x_))\n",
    "\n",
    "y_sum = y_.summary_frame(alpha=0.05)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# data\n",
    "ax.scatter(X, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(x_, y_sum['mean'])\n",
    "\n",
    "# confidence interval\n",
    "ax.fill_between(x_, y_sum['mean_ci_lower'], y_sum['mean_ci_upper'],\n",
    "                lw=0, color='#34675c', alpha=0.4, label='CI 95%')\n",
    "\n",
    "ax.set_xlabel('TotalSleep')\n",
    "ax.set_ylabel('LifeSpan')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ba2ae",
   "metadata": {},
   "source": [
    "睡眠時間（TotalSleep）の値が小さいほど、誤差が大きくなる傾向が見られます。次に、この誤差の分布を可視化し、詳しく評価していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = y - fit_lm.predict(sm.add_constant(X))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot([X.min(), X.max()], [0, 0])\n",
    "ax1.vlines(X, 0, err, linestyles='dashed')\n",
    "ax1.scatter(X, err)\n",
    "ax1.set_xlabel('TotalSleep')\n",
    "ax1.set_ylabel('error')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.hist(err)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a42e6",
   "metadata": {},
   "source": [
    "残差プロットを見ると、睡眠時間（TotalSleep）が短いほど誤差（残差）が大きくなることが確認できます。また、誤差の分布を確認すると、ピークは 0 に近いものの、右側の裾が長くなっており、正規分布からはかけ離れています。つまり、このモデルは妥当とは言いにくい状況です。\n",
    "\n",
    "そこで、目的変数を対数変換してスケールを小さくし、再度同様の回帰分析を行ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log10(msleep['LifeSpan'])\n",
    "X = msleep['TotalSleep']\n",
    "\n",
    "m_loglm = sm.GLM(y, sm.add_constant(X))\n",
    "fit_loglm = m_loglm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(X.min(), X.max(), 100)\n",
    "y_ = fit_loglm.get_prediction(sm.add_constant(x_))\n",
    "\n",
    "y_sum = y_.summary_frame(alpha=0.05)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# data\n",
    "ax.scatter(X, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(x_, y_sum['mean'])\n",
    "\n",
    "# confidence interval\n",
    "ax.fill_between(x_, y_sum['mean_ci_lower'], y_sum['mean_ci_upper'],\n",
    "                lw=0, color='#34675c', alpha=0.4, label='CI 95%')\n",
    "\n",
    "ax.set_xlabel('TotalSleep')\n",
    "ax.set_ylabel('log10(LifeSpan)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = y - fit_loglm.predict(sm.add_constant(X))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot([X.min(), X.max()], [0, 0])\n",
    "ax1.vlines(X, 0, err, linestyles='dashed')\n",
    "ax1.scatter(X, err)\n",
    "ax1.set_xlabel('TotalSleep')\n",
    "ax1.set_ylabel('error')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.hist(err)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db890ee2",
   "metadata": {},
   "source": [
    "このように、目的変数を対数化することで、予測誤差が小さくなるだけでなく、誤差項の分布も正規分布に近づいているように見えます。その結果、モデル全体の性能が大きく改善されました。\n",
    "\n",
    "今回のモデルは、変数変換を行ったうえで回帰分析を実施しているため、次のような式で表されます。\n",
    "\n",
    "$$\n",
    "\\log \\text{LifeSpan} = \\beta_{0} + \\beta_{1} \\text{TotalSleep}\n",
    "$$\n",
    "\n",
    "この考え方が一般化線形モデルの基本となっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c17aa",
   "metadata": {},
   "source": [
    "## 一般化線形モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a84174",
   "metadata": {},
   "source": [
    "一般化線形モデル（GLM）は、**線形予測子**（**linear predictor**）、**リンク関数**（**link function**）、および**誤差構造**（**error structure**）の3つの要素から構成されます。線形予測子とは、説明変数と係数の一次結合で表される数式です。たとえば、$n$ 個の説明変数 $X_{1}, X_{2}, \\cdots, X_{n}$ に対して、\n",
    "\n",
    "$$\n",
    "\\eta = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\cdots + \\beta_{n}X_{n}\n",
    "$$\n",
    "\n",
    "と表され、この $\\eta$ が線形予測子です。\n",
    "\n",
    "リンク関数は、目的変数の期待値（平均）と線形予測子を対応付ける関数です。以下のように表されます。\n",
    "\n",
    "$$\n",
    "g(\\mathbb{E}[Y]) = \\eta\n",
    "$$\n",
    "\n",
    "ここで、$g$ はリンク関数であり、モデルによって適切な関数が選ばれます。たとえば、ロジスティック回帰ではロジット関数などが選ばれます。\n",
    "\n",
    "誤差構造とは、目的変数 $Y$ の確率分布のことです。これは、目的変数のばらつき（分散）をどのようにモデル化するかという重要な要素です。たとえば、目的変数のばらつきが一定（等分散）と考えられる場合には、正規分布が適用され、これは通常の線形回帰に相当します。一方、個体数などの計数データでは、値が大きくなるほど分散も大きくなる傾向があります。このような場合、目的変数はポアソン分布や負の二項分布に従うと仮定し、分散が平均値に比例あるいはより大きくなるような誤差構造を導入します。さらに、目的変数が陽性・陰性などの二値データである場合、目的変数はベルヌーイ分布や二項分布に従うと仮定します。\n",
    "\n",
    "一般的に、誤差構造を決めると、使用可能なリンク関数も限定されます。以下は、statsmodels ライブラリで指定できる誤差構造とリンク関数の組み合わせです。\n",
    "\n",
    "| 誤差構造           | リンク関数 |\n",
    "|------------------|------------|\n",
    "| Poisson          | identity, log, sqrt |\n",
    "| Binomial         | identity, log, cauchy, logit, probit, cloglog |\n",
    "| Gamma            | identity, log, inverse_power |\n",
    "| Gaussian         | identity, log, inverse_power |\n",
    "| InverseGaussian  | identity, log, inverse_power, inverse_squared|\n",
    "| NegativeBinomial | identity, log, cloglog, nbinom, Power |\n",
    "| Tweedie          | identity, log, Power |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a398e88",
   "metadata": {},
   "source": [
    "## ポアソン回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b33003",
   "metadata": {},
   "source": [
    "上の例からもわかるように、寿命（LifeSpan）の値が大きくなるほど、そのばらつきも大きくなる傾向が見られます。このように、値が大きくなるにつれてばらつきも増加するようなデータをモデリングする場合には、ポアソン回帰がよく用いられます。ここでは、ポアソン回帰を使って、睡眠時間（TotalSleep）から寿命（LifeSpan）を説明する回帰モデルを構築してみましょう。ポアソン回帰では、リンク関数として対数関数を用いるのが一般的です。\n",
    "\n",
    "リンク関数が対数関数であるため、概念的には次のような式でモデルが構築されていることになります。\n",
    "\n",
    "$$\n",
    "\\log Y = \\eta = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\cdots + \\beta_{n}X_{n}\n",
    "$$\n",
    "\n",
    "つまり、これは前の例で見たように、目的変数を対数変換してから線形回帰を行っているのとほぼ同じことを意味します。\n",
    "\n",
    "`GLM` 関数では、`family` オプションを使って誤差構造を指定します。また、誤差構造を生成する際に、使用するリンク関数も一緒に指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = msleep['LifeSpan']\n",
    "X = msleep['TotalSleep']\n",
    "\n",
    "link = sm.families.links.Log()\n",
    "family = sm.families.Poisson(link)\n",
    "\n",
    "m_poisson = sm.GLM(y, sm.add_constant(X), family=family)\n",
    "fit_poisson = m_poisson.fit()\n",
    "\n",
    "fit_poisson.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af381e3",
   "metadata": {},
   "source": [
    "次に、観測値に加えて、モデルによる回帰直線、信頼区間、および予測区間を可視化します。なお、`GLM` 関数で生成されたオブジェクトでは、予測区間を自動的に計算することはできないため、ここでは予測区間と信頼区間を計算する関数をあらかじめ定義しておく必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def summarize_poisson_model(x, model, link):\n",
    "    x_ = sm.add_constant(x)\n",
    "    eta = model.predict(x_, linear=True)\n",
    "    cov = model.cov_params()\n",
    "    se_eta = np.sqrt(np.sum(x_ @ cov * x_, axis=1))\n",
    "\n",
    "    z = norm.ppf(0.975)\n",
    "\n",
    "    # predicted y\n",
    "    mean_pred = link.inverse(eta)\n",
    "\n",
    "    # CI\n",
    "    eta_lw = eta - z * se_eta\n",
    "    eta_up = eta + z * se_eta\n",
    "    ci_lw = link.inverse(eta_lw)\n",
    "    ci_up = link.inverse(eta_up)\n",
    "\n",
    "    # PI\n",
    "    var_pred = se_eta**2 + 1 / mean_pred\n",
    "    pi_lw = np.exp(eta - z * np.sqrt(var_pred))\n",
    "    pi_up = np.exp(eta + z * np.sqrt(var_pred))\n",
    "\n",
    "    return pd.DataFrame({'x': x, 'y': mean_pred,\n",
    "                         'ci_lw': ci_lw, 'ci_up': ci_up,\n",
    "                         'pi_lw': pi_lw, 'pi_up': pi_up})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc87c85",
   "metadata": {},
   "source": [
    "この関数を利用して、モデルの可視化を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81661fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(X.min(), X.max(), 100)\n",
    "y_ = summarize_poisson_model(x_, fit_poisson, link)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# data\n",
    "ax.scatter(X, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(y_['x'], y_['y'])\n",
    "\n",
    "# prediction interval\n",
    "ax.fill_between(x_, y_['pi_lw'], y_['pi_up'],\n",
    "                lw=0, color='#426e86', alpha=0.2, label='PI 95%')\n",
    "\n",
    "# confidence interval\n",
    "ax.fill_between(x_, y_['ci_lw'], y_['ci_up'],\n",
    "                lw=0, color='#34675c', alpha=0.4, label='CI 95%')\n",
    "\n",
    "ax.set_xlabel('TotalSleep')\n",
    "ax.set_ylabel('LifeSpan')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc8e39",
   "metadata": {},
   "source": [
    "このように、ポアソン回帰を行うことで、モデルの予測値は直線的ではなく、目的変数に応じて非線形に変化することがわかります。また、信頼区間および予測区間に注目すると、目的変数の値が大きくなるにつれて、それらの区間も徐々に広がっていることが確認できます。\n",
    "\n",
    "一方で、予測区間を確認すると、多くの観測点がその範囲の外側に位置していることがわかります。これは、モデルが実際の測定値に対して適切に適合できていないことを示しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bda07d-2924-4104-9ada-fed732a16233",
   "metadata": {},
   "source": [
    "## 負の二項分布回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0aac0",
   "metadata": {},
   "source": [
    "ポアソン回帰でうまくモデル化できないデータについては、誤差構造を負の二項分布にすることで改善される場合が多くあります。負の二項分布には、大きなばらつき（過分散）を扱える項が含まれており、ポアソン分布より柔軟にデータを表現できます。ただし、この過分散を許容するパラメーター（`alpha`）は、自動的には推定されません。解析者が事前に値を指定する必要があります。\n",
    "\n",
    "たとえば、`alpha=0.1` を指定してモデルを構築する場合、以下のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = msleep['LifeSpan']\n",
    "X = msleep['TotalSleep']\n",
    "\n",
    "link = sm.families.links.Log()\n",
    "family = sm.families.NegativeBinomial(link, alpha=0.1)\n",
    "\n",
    "m_nb = sm.GLM(y, sm.add_constant(X), family=family)\n",
    "fit_nb = m_nb.fit()\n",
    "\n",
    "fit_nb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73311e7d",
   "metadata": {},
   "source": [
    "続いて、モデルを可視化します。ただし、誤差構造にポアソン分布を用いた場合と、負の二項分布を用いた場合とでは、予測区間の計算方法が異なるため、信頼区間および予測区間を算出する関数をあらためて用意する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37df0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_nb_model(x, model, link):\n",
    "    x_ = sm.add_constant(x)\n",
    "    eta = model.predict(x_, linear=True)\n",
    "    cov = model.cov_params()\n",
    "    if cov.shape[0] != x_.shape[1]:\n",
    "        # object from NegativeBinomial contains estimated 'alpha' \n",
    "        cov = cov.iloc[0:-1, 0:-1]\n",
    "    se_eta = np.sqrt(np.sum(x_ @ cov * x_, axis=1))\n",
    "\n",
    "    if hasattr(model, 'family') and hasattr(model.family, 'alpha'):\n",
    "        # object from GLM\n",
    "        alpha = model.family.alpha\n",
    "    else:\n",
    "        # object from NegativeBinomial\n",
    "        alpha = model.params[-1]\n",
    "\n",
    "    z = norm.ppf(0.975)\n",
    "\n",
    "    # predicted y\n",
    "    mean_pred = link.inverse(eta)\n",
    "    \n",
    "    # CI\n",
    "    eta_lw = eta - z * se_eta\n",
    "    eta_up = eta + z * se_eta\n",
    "    ci_lw = link.inverse(eta_lw)\n",
    "    ci_up = link.inverse(eta_up)\n",
    "    \n",
    "    # PI\n",
    "    var_pred = mean_pred + alpha * mean_pred ** 2\n",
    "    se_log_pred = np.sqrt(var_pred) / mean_pred\n",
    "    pred_lw = eta - z * se_log_pred\n",
    "    pred_up = eta + z * se_log_pred\n",
    "    pi_lw = link.inverse(pred_lw)\n",
    "    pi_up = link.inverse(pred_up)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': mean_pred,\n",
    "        'ci_lw': ci_lw,\n",
    "        'ci_up': ci_up,\n",
    "        'pi_lw': pi_lw,\n",
    "        'pi_up': pi_up\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "x_ = np.linspace(X.min(), X.max(), 100)\n",
    "y_ = summarize_nb_model(x_, fit_nb, link)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# data\n",
    "ax.scatter(X, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(y_['x'], y_['y'])\n",
    "\n",
    "# prediction interval\n",
    "ax.fill_between(x_, y_['pi_lw'], y_['pi_up'],\n",
    "                lw=0, color='#426e86', alpha=0.2, label='PI 95%')\n",
    "\n",
    "# confidence interval\n",
    "ax.fill_between(x_, y_['ci_lw'], y_['ci_up'],\n",
    "                lw=0, color='#34675c', alpha=0.4, label='CI 95%')\n",
    "\n",
    "ax.set_xlabel('TotalSleep')\n",
    "ax.set_ylabel('LifeSpan')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c220502",
   "metadata": {},
   "source": [
    "予測区間を確認すると、ポアソン回帰と比較して改善は見られるものの、依然として多くの観測値が予測区間の外側にあることがわかります。このことから、モデルにはさらなる改善の余地があると考えられます。\n",
    "\n",
    "このモデルの AIC は、以下の方法で取得できます。AIC はモデルの適合度を評価する指標で、値が小さいほどモデルの適合度が高く、より適切であることを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfcb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_nb.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edaf39",
   "metadata": {},
   "source": [
    "\n",
    "次に取るべきアプローチとしては、`alpha `の値を調整して複数のモデルを再構築し、それぞれの AIC を比較することが挙げられます。これにより、AIC が最小となる `alpha` を見つけ出し、最適なモデルを選択することが可能になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985daa47-8c0e-45f5-9a60-b834923a6222",
   "metadata": {},
   "source": [
    "```{admonition} 練習問題 SGL-1\n",
    "動物の睡眠時間に関するデータセット msleep.txt を読み込み、睡眠時間（TotalSleep）を用いて寿命（LifeSpan）を説明する回帰モデルを構築しなさい。このとき、誤差構造には負の二項分布を、リンク関数には対数関数を使用してください。また、`GLM` 関数の `alpha` パラメーターの値を 0.01、0.1、1、10 に変更しながら分析を行い、それぞれの場合における信頼区間や予測区間の変化について簡単に述べなさい。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a4d34",
   "metadata": {},
   "source": [
    "`GLM` 関数では、`alpha` を解析者が指定する必要がありましたが、statsmodels ライブラリの api モジュールにある `NegativeBinomial` 関数を使うことで、`alpha` を自動的に推定することが可能です。以下にその例を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567164d2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "m_nb = sm.NegativeBinomial(y, sm.add_constant(X))\n",
    "fit_nb = m_nb.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db05133",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "glue('nb_alpha', round(float(fit_nb.params[-1]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f463d",
   "metadata": {},
   "source": [
    "推定結果を確認してみましょう。定数項および説明変数の係数に加え、`alpha` も {glue}`nb_alpha` と推定されていることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_nb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d20bc9e",
   "metadata": {},
   "source": [
    "次に、構築したモデルを可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae586bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.linspace(X.min(), X.max(), 100)\n",
    "y_ = summarize_nb_model(x_, fit_nb, link)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# data\n",
    "ax.scatter(X, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(y_['x'], y_['y'])\n",
    "\n",
    "# prediction interval\n",
    "ax.fill_between(x_, y_['pi_lw'], y_['pi_up'],\n",
    "                lw=0, color='#426e86', alpha=0.2, label='PI 95%')\n",
    "\n",
    "# confidence interval\n",
    "ax.fill_between(x_, y_['ci_lw'], y_['ci_up'],\n",
    "                lw=0, color='#34675c', alpha=0.4, label='CI 95%')\n",
    "\n",
    "ax.set_xlabel('TotalSleep')\n",
    "ax.set_ylabel('LifeSpan')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e5d9e",
   "metadata": {},
   "source": [
    "可視化の結果から、ほとんどの観測点が予測区間内に収まっていることが確認できました。また、AIC の値を確認しても、`NegativeBinomial` 関数を用いて自動的に `alpha` を推定したモデルは、`GLM` 関数を用いて `alpha = 0.1` と固定したモデルよりも適合度が高いことがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe035bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_nb.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f7ece",
   "metadata": {},
   "source": [
    "## ロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17387c40",
   "metadata": {},
   "source": [
    "ロジスティック回帰は、生物学や農学において、2 値の事象（例：生存／死亡、発芽／不発芽、感染／非感染）を説明するために広く用いられている統計手法です。ここでは、開花を制御する遺伝子の発現量が植物の開花にどのような影響を与えるかについて、ロジスティック回帰を用いて調べる例を紹介します。\n",
    "\n",
    "まず、開花に関するデータセットを読み込みます。このデータセットには 3 列の情報が含まれており、最初の 2 列は開花を制御する遺伝子である ft と ap1 の発現量、3 列目は遺伝子発現を測定した時点でその植物が開花していたかどうか（1 は開花、0 は未開花）を示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://py.biopapyrus.jp/data/flowering.txt\n",
    "flowering = pd.read_csv('flowering.txt', sep='\\t')\n",
    "flowering.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ee3bf",
   "metadata": {},
   "source": [
    "説明を簡単にするため、ここでは ft 遺伝子の発現量のみに着目して、開花の有無を説明するロジスティック回帰モデルを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flowering['ft']\n",
    "y = flowering['flowering']\n",
    "\n",
    "link = sm.families.links.Logit()\n",
    "family = sm.families.Binomial(link)\n",
    "\n",
    "m = sm.GLM(y, sm.add_constant(X), family=family)\n",
    "fit = m.fit()\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b5088",
   "metadata": {},
   "source": [
    "次に、観測値とモデルの予測値をグラフに描いて、モデルを可視化します。なお、ロジスティック回帰では目的変数が 0 または 1 の値しか取らないため、通常は予測区間を描画しません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_logit_model(x, model, link):\n",
    "    x_ = sm.add_constant(x)\n",
    "    \n",
    "    eta = model.predict(x_, linear=True)\n",
    "    cov = model.cov_params()\n",
    "    se_eta = np.sqrt(np.sum(x_ @ cov * x_, axis=1))\n",
    "\n",
    "    z = norm.ppf(0.975)\n",
    "\n",
    "    mean_pred = link.inverse(eta)\n",
    "\n",
    "    eta_lw = eta - z * se_eta\n",
    "    eta_up = eta + z * se_eta\n",
    "    ci_lw = link.inverse(eta_lw)\n",
    "    ci_up = link.inverse(eta_up)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': mean_pred,\n",
    "        'ci_lw': ci_lw,\n",
    "        'ci_up': ci_up\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_ = np.linspace(X.min(), X.max(), 100)\n",
    "y_ = summarize_logit_model(x_, fit, link)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# data\n",
    "ax.scatter(X, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(y_['x'], y_['y'])\n",
    "\n",
    "# confidence interval\n",
    "ax.fill_between(x_, y_['ci_lw'], y_['ci_up'],\n",
    "                lw=0, color='#34675c', alpha=0.4, label='CI 95%')\n",
    "\n",
    "ax.set_xlabel('expression')\n",
    "ax.set_ylabel('flowering')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e56876",
   "metadata": {},
   "source": [
    "このように、ft 遺伝子の発現量が 30 を超えるあたりから、半数以上の個体が開花していることがわかります。さらに、発現量が 40 以上になると、約 8 割以上の個体が開花しています。この結果から、ft 遺伝子の発現量が植物の開花に強く影響を与えていることが読み取れます。\n",
    "\n",
    "```{admonition} 練習問題 SGL-2\n",
    "植物開花データセット flowering.txt を用いて、ft 遺伝子のみ、ap1 遺伝子のみ、そして両者を同時に用いたロジスティック回帰モデルを構築しなさい。それぞれのモデルについて、AIC などの指標を用いて最適なモデルを選択してください。\n",
    "```\n",
    "\n",
    "結果が綺麗すぎるって？当然でしょ。これは著者が現実を削って作った、夢の世界。実務では、結果どころか、データさえ読み込めないこともあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4c67b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!rm msleep.txt\n",
    "!rm flowering.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
